{
  "train_datasets": [
    {
      "name": "next_qa_oe",
      "txt": {
        "next_qa_oe": "/path/to/your/data/NExT-QA/nextqa_oe/train.csv"
      },
      "img": "/path/to/your/data/VidOR/video"
    }
  ],
  "val_datasets": [
    {
      "name": "next_qa_oe",
      "txt": {
        "next_qa_oe": "/path/to/your/data/NExT-QA/nextqa_oe/val.csv"
      },
      "img": "/path/to/your/data/VidOR/video"
    }
  ],
  "map_vid_vidorID_path": "/path/to/your/data/NExT-QA/map_vid_vidorID.json",
  "ref_answer_add_path": "/path/to/your/data/NExT-QA/nextqa_oe/add_reference_answer_test.json",
  "ans2label_path": "/path/to/your/data/NExT-QA/nextqa_oe/vocab.pkl",
  "max_txt_len": 40,
  "crop_img_size": 224,
  "resize_size": 256,
  "img_pixel_mean": [0.48145466, 0.4578275, 0.40821073],
  "img_pixel_std": [0.26862954, 0.26130258, 0.27577711],
  "img_input_format": "RGB",
  "train_n_clips": 1,
  "num_frm": 16,
  "model_config": "config/base_model.json",
  "tokenizer_dir": "/path/to/your/data//mcg/ext/bert-base-uncased",
  "visual_model_cfg": "config/timesformer_divst_8x32_224_k600_gc.json",
  "e2e_weights_path": "/path/to/your/data/mcg/pretrain/mcg_pretrained_ckpt.pt",
  "LM_weights_path": "/path/to/your/data/mcg/ext/model_base_14M.pth",
  "LM_weights_cfg": "config/med_config.json",
  "train_batch_size": 8,
  "val_batch_size": 8,
  "gradient_accumulation_steps": 2,
  "num_train_epochs": 10,
  "min_valid_steps": 20,
  "num_valid": 50,
  "learning_rate": 5e-6,
  "weight_decay": 1e-3,
  "decay": "linear",
  "optim": "adamw",
  "betas": [0.9, 0.98],
  "dropout": 0.1,
  "grad_norm": 5.0,
  "cnn_lr_decay": "linear",
  "seed":42,
  "fp16": 0,
  "cls_hidden_scale": 2,
  "task": "next_qa_oe",
  "num_workers": 4
}
